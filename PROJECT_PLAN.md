# Baseball RAG Agent - Project Plan

**Version:** 2.0  
**Last Updated:** December 2024  
**Status:** MVP Complete - Real-time Streaming Chat Interface

## Project Overview

Build a locally-hosted RAG system that answers complex baseball questions using real FanGraphs data and advanced retrieval techniques. The system prioritizes accuracy over speed, runs entirely on localhost, and uses incremental development.

### Core Principles
1. **Accuracy over speed** - Use real data, not LLM hallucinations
2. **Local-first** - No cloud dependencies, runs entirely on localhost  
3. **Separation of concerns** - R for data, TypeScript for application logic
4. **Incremental development** - Ship working features, iterate later

## Architecture Overview

```
Data Sources (FanGraphs) ‚Üí R ETL ‚Üí PostgreSQL + PGVector ‚Üí TypeScript Backend ‚Üí React Frontend
                                        ‚Üì
                                   Ollama LLM ‚Üê Semantic Search + Tool Calling
```

**Key Technologies:**
- **Data Pipeline**: R + baseballr ‚Üí PostgreSQL 16 + pgvector
- **Backend**: TypeScript/Node.js + Fastify + Ollama integration  
- **Frontend**: React + TypeScript + Material UI
- **AI**: Local LLM (llama3.2) + transformers.js embeddings
- **Search**: Hybrid semantic + SQL filtering

## Development Phases

### ‚úÖ Phase 1: MVP Complete
**Status:** Full end-to-end RAG system with real-time streaming

**Completed Components:**
- **Data Pipeline** ([fangraphs/](fangraphs/)) - FanGraphs ETL with 20-80 scouting grades
- **Embeddings** ([embeddings/](embeddings/)) - Semantic search with hybrid filtering  
- **Backend API** ([backend/](backend/)) - LLM orchestration with tool calling
- **Frontend** ([frontend/](frontend/)) - Real-time streaming chat interface
- **Database** ([database/](database/)) - PostgreSQL schema with performance indexes

**Key Features:**
- Real-time streaming responses with tool execution indicators
- Hybrid search (semantic similarity + SQL grade filtering)
- 35+ years of FanGraphs batting data (1988-2025)
- Tool-based retrieval with citation support
- SMS-style chat interface with markdown rendering

### üéØ Phase 2: Enhanced Retrieval
**Status:** Planned - Addresses current search limitations

**Objectives:**
- **Full-text search** for short/keyword queries ("all time great shortstops")
- **Cross-encoder reranking** for better precision on complex queries  
- **Two-stage retrieval** pipeline (fast recall + precise ranking)

**Technical Approach:**
1. **Stage 1 - Fast Retrieval**: FTS for short queries, vector for long queries
2. **Stage 2 - Precise Reranking**: Cross-encoder for top candidates
3. **Query Router**: Automatically choose best search method

**Benefits:**
- Solves bi-encoder limitations (opposites, negation, length bias)
- Handles complex queries: "power WITHOUT speed", "elite defense BUT poor offense"
- Better keyword matching for baseball terminology

### üìã Phase 3+: Future Features
- **Percentile rankings** with visual profiles (requires Statcast integration)
- **Pitcher data** and analysis
- **Baseball Reference integration** for biographical data
- **Interactive visualizations** generated by R
- **Multi-turn conversations** with memory

## Key Architecture Decisions

### 1. **R for ETL, TypeScript for Application**
**Rationale:** R excels at statistical analysis with mature baseball packages (`baseballr`). TypeScript provides type safety for complex application logic.

**Trade-offs:** Two language ecosystems, more complex deployment. Worth it for leveraging best-in-class tools.

### 2. **Grades Calculated in R ETL**
**Current:** Era-adjusted "plus" stats with standard deviation thresholds  
**Future (Phase 3):** Percentile-based calculation for statistical accuracy

**Benefits:** Single source of truth, enables SQL filtering, validates distributions during ETL

### 3. **Hybrid Search (Semantic + SQL Filters)**
**Rationale:** Pure semantic search doesn't respect hard constraints (position, grade thresholds). Combining vector similarity with SQL filters gives best of both worlds.

**Implementation:**
```sql
-- Semantic similarity + hard filters
WHERE embedding <=> query_embedding  -- Vector search
  AND position ILIKE '%1B%'          -- SQL filter
  AND power_grade >= 60              -- SQL filter
ORDER BY embedding <=> query_embedding
```

### 4. **PGVector over Specialized Vector DBs**
**Rationale:** Single database for structured stats AND vectors enables hybrid queries. Better for production scaling with mature PostgreSQL ecosystem.

**Trade-offs:** More complex setup vs ChromaDB, but worth it for query flexibility.

### 5. **Ollama over Cloud LLMs**
**Rationale:** Fully local (no API costs), privacy control, fast iteration. Good models available (llama3.2, qwen2.5).

**Trade-offs:** Requires GPU, lower quality ceiling than GPT-4. Worth it for local-first principle.

### 6. **Two-Stage Retrieval (Phase 2)**
**Problem:** Bi-encoders can't distinguish opposites ("all time great" matches "replacement level" due to structural similarity).

**Solution:** 
- **Stage 1:** Fast retrieval (FTS/vector) for 50-100 candidates
- **Stage 2:** Cross-encoder reranking for top 10 with full attention

**Benefits:** Handles negation, opposites, multi-constraint queries while maintaining speed.

## Technical Documentation

Detailed technical specifications are distributed across project folders:

- **[fangraphs/README.md](fangraphs/)** - ETL pipeline, R setup, grade calculation
- **[embeddings/README.md](embeddings/)** - Semantic search, model details, CLI usage  
- **[backend/README.md](backend/)** - API documentation, LLM integration, streaming
- **[frontend/README.md](frontend/)** - UI components, chat interface, build process
- **[database/README.md](database/)** - Schema, indexes, performance tuning

## Lessons Learned

### Data & ETL
- **FanGraphs API quirks**: Doesn't handle multi-year requests, requires year-by-year iteration
- **Grade distribution validation**: Critical for catching calculation errors (~10% should get 70+ grades)
- **Incremental ETL essential**: Preserves manual corrections, faster updates

### Search & Embeddings  
- **Length normalization bias**: Short queries match sparse descriptions better than dense ones
- **Bi-encoder limitations**: Can't distinguish opposites or handle negation effectively
- **Template summaries work well**: Consistent format, good semantic matching without LLM overhead
- **Hybrid search essential**: Pure semantic search ignores hard constraints (position, grades)

### LLM Integration
- **Tool calling complexity**: Parameter ordering and extraction can be fragile
- **Streaming adds value**: Real-time feedback significantly improves perceived performance  
- **Prompt engineering is iterative**: Initial prompts work but need refinement for better presentation
- **Local models sufficient**: llama3.2 handles baseball queries well with proper tool integration

### Frontend & UX
- **SMS-style familiar**: Users immediately understand blue/gray bubble interface
- **Streaming implementation complex**: Dual loops (pre-tools + post-tools) with proper buffering
- **Material UI accelerates development**: Pre-built components with consistent theming
- **Loading states prevent confusion**: "Thinking..." spinner sets proper expectations

### Performance & Infrastructure
- **Structured logging invaluable**: Request tracing, performance metrics, error context essential for debugging
- **Connection pooling critical**: Database performance degrades quickly without proper pooling
- **Indexes make or break queries**: Grade filtering requires proper indexes for hybrid search performance
- **Docker simplifies deployment**: Consistent environment across development and production

## Current Limitations

- **Batter data only** - No pitcher statistics yet
- **FanGraphs only** - Missing Baseball Reference biographical data  
- **Single-stage search** - Bi-encoder limitations with opposites and negation
- **Template summaries** - Fixed format vs dynamic LLM-generated descriptions
- **Known tool issues** - Some parameter extraction and filtering edge cases

## Performance Metrics

- **Query time**: 1-3 seconds for complex questions
- **Database**: 50K player-seasons, 15K unique players (1988-2025)
- **Search**: ~100ms semantic, ~200ms hybrid with filters
- **Embeddings**: 768-dimensional vectors, ~420MB model
- **Streaming**: Real-time token display with 50ms buffering

## Next Steps

1. **Phase 2 Planning** - Design FTS + reranking architecture
2. **Search Quality Evaluation** - Benchmark current vs proposed approaches  
3. **Cross-encoder Integration** - Implement and test reranking models
4. **Query Router Logic** - Automatic selection of search strategy
5. **Performance Optimization** - Target <1 second total retrieval time

---

**For detailed technical implementation, see individual project READMEs linked above.**